<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <link rel="stylesheet" href="css/main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>

    <title>Aris Malapaschas, PhD</title>


  </head>

  <body>

<!-- **************** NAVBAR **************** -->
  <div class="container-fluid header pt-2 pb-1">
    <h1 class="display-5">Aris Malapaschas</h1>
    <h5>Human-Computer Interaction Researcher</h5>
  </div>

  <nav class="navbar navbar-expand-sm pt-0 m-0">
    <ul class="navbar-nav ml-auto pr-2">
      <li class="nav-item">
        <a class="nav-link nav-link2 py-0" href="./index.html">Home</a>
      </li>
      <li class="nav-item">
        <a class="nav-link nav-link2 py-0 nav-link-active" href="./uxresearch.html">UX Research</a>
      </li>
      <li class="nav-item">
        <a class="nav-link nav-link2 py-0" href="./about.html">About</a>
      </li>
    </ul>
  </nav>
<!-- **************** NAVBAR **************** -->


<div class="container-fluid main">
  <div class="container p-5">

  <!-- **************** ACCORDION 1 **************** -->
    <div class="container pb-2">
      <h2>Voice Assistants for People with Acquired Brain Injury</h2>
    </div>

    <div id="accordion1" class="px-2">

      <div class="card">
        <div class="card-header">
          <a class="card-link" data-toggle="collapse" href="#collapseOne">
            <b>1. Effects of Acquired Brain Injury and the Use of External Aids</b>
          </a>
        </div>
        <div id="collapseOne" class="collapse  show" data-parent="#accordion1">
          <div class="card-body p-2">


            <ul class="nav nav-tabs" role="tablist">
              <li class="nav-item">
                <a class="nav-link active" href="#overview11" role="tab" data-toggle="tab">Overview</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#methods11" role="tab" data-toggle="tab">Methods</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#results11" role="tab" data-toggle="tab">Results</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#graphs11" role="tab" data-toggle="tab">Graphs & Charts</a>
              </li>
            </ul>

            <!-- Tab panes -->
            <div class="container p-0">
              <div class="tab-content">
                <div role="tabpanel" class="tab-pane active p-3" id="overview11">
                  <p>
                    Acquired Brain Injury (<b>ABI</b>) causes a wide range of cognitive and physical impairments, which can affect the person’s ability to perform everyday tasks, and reduce their independence. The use of external aids (both paper-based and technological tools) can improve everyday functioning and facilitate the rehabilitation process, however research shows the existence of several barriers that can prevent their uptake and efficient use.
                  </p>
                  <p>
                    Two requirements-capturing studies were conducted to: 1) identify the situations where there is a need for technological aids and what would their intended purpose be; 2) to further examine the common cognitive effects of ABI; 3) To explore how the effects of ABI affect the usability of existing external aids.
                  </p>
                  A case-study report of both studies can be found <a href="1.ABI_effects&AT.pdf" target="_blank">here.</a>
                  More details <a href="2021malapaschasphd.pdf#page=62" target="_blank">here.</a>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="methods11">
                  <h5>Study 1 - Online Survey</h5>
                  <p>An online survey with n=99 brain injury survivors from different English speaking countries, to gather general information about the experience of brain injury and the use of technological aids.
                    The questionnaire consisted of six sections covering the following topics: 1) demographic information; 2) Memory performance; 3) Executive function; 4) Motivation and activeness; 5) Rehabilitation, and 6) Use of external aids (paper-based tools, electronic devices with a screen, and Voice Assistants).
                  </p>
                  <p>5-point Likert scales were used to indicate the frequency of everyday issues resulting from the effects of brain injury, the frequency of use of the different types of external aids and the participants’ subjective evaluation of their effectiveness.
                    Non-parametric statistical tests were used to investigate the correlation between answers to different questions of the survey, and to examine the difference between subgroups within the sample.
                  </p>
                  <h5>Study 2 - Group Interview with neuropsychologists</h5>
                  <p>
                    A group interview with n=7 neuropsychologists running a ehabilitation centre for brain injury survivors.
                    The interview was conducted in a semi- structured way, with questions evolving around the effects of ABI, methods of neuropsychological rehabilitation, and the design of assistive technologies. Inductive thematic analysis was used to analyse the recorded data.
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="results11">
                  <p>The results of these two studies were analysed to create a set of use cases and a set of design characteristics for Assistive Technologies for people with Acquired Brain Injury:</p>
                  <h5>Use Cases of Assistive Technologies for People with ABI</h5>
                  <ul class="list-group list-group-flush">
                    <li class="list-group-item list-group-item-secondary">1. Support impaired cognitive functions such as memory, organisation, initiation and motivation through timely cues to prompt action.</li>
                    <li class="list-group-item list-group-item-secondary">2. Increase awareness of inappropriate behaviour through regular prompting.</li>
                    <li class="list-group-item list-group-item-secondary">3. Facilitate communication between family members/carers and people with ABI to improve support and reduce conflicts.</li>
                    <li class="list-group-item list-group-item-secondary">4. Facilitate collaboration between family members/carers and therapists to improve mon- itoring, assessment and support.</li>
                    <li class="list-group-item list-group-item-secondary">5. Support engagement to the rehabilitation process by increasing motivation through goal completion.</li>
                    <li class="list-group-item list-group-item-secondary">6. Increase activeness and participation in social activities.</li>
                    <li class="list-group-item list-group-item-secondary">7. Facilitate task completion through suitable guidance, and by supporting concentration and attention.</li>
                  </ul>
                  <br>
                  <h5>Design Characteristics of Assistive Technologies for People with ABI</h5>
                  <ul class="list-group list-group-flush">
                    <li class="list-group-item list-group-item-secondary"><b>Personalisable</b>: Offer customisation to support users with different levels of impairment, cognitive capabilities and rehabilitation goals.</li>
                    <li class="list-group-item list-group-item-secondary"><b>Adaptive</b>: Automatically adjust the content of prompting based on the context and the user’s behaviour./li>
                    <li class="list-group-item list-group-item-secondary"><b>Trustworthy</b>: Provide support in a friendly and intimate manner that appeals to the individual and inspires trust.</li>
                    <li class="list-group-item list-group-item-secondary"><b>Discrete</b>: Provide efficient prompting in a discrete manner that avoids unwanted attention and social embarrassment.</li>
                    <li class="list-group-item list-group-item-secondary"><b>Rewarding</b>: Provide a goal-oriented sense of achievement and positive reinforce- ment to increase motivation.</li>
                    <li class="list-group-item list-group-item-secondary"><b>Simple</b>: Use concise and straightforward interaction to support users with lim- ited cognitive capacity.</li>
                    <li class="list-group-item list-group-item-secondary"><b>Autonomous</b>: Provide timely support without relying on the user’s input and initiative.</li>
                  </ul>
                </div>
                <div role="tabpanel" class="tab-pane fade pt-3" id="graphs11">


                  <div class="container p-3">
                    <div class="row">
                      <div class="col-sm">
                        <a href="./images/study1/chart1-memory.png" class="pop" target="_blank">
                          <img src="images/study1/chart1-memory.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study1/chart2-execfunc.png" class="pop" target="_blank">
                          <img src="images/study1/chart2-execfunc.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study1/chart3-active.png" class="pop" target="_blank">
                          <img src="images/study1/chart3-active.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study1/table1.png" class="pop" target="_blank">
                          <img src="images/study1/table1.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                    </div>
                    <div class="row pt-3">
                      <div class="col-sm">
                        <a href="./images/study1/table3.png" class="pop" target="_blank">
                          <img src="images/study1/table3.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study1/chart4-effort.png" class="pop" target="_blank">
                          <img src="images/study1/chart4-effort.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study1/chart5-vas.png" class="pop" target="_blank">
                          <img src="images/study1/chart5-vas.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study1/chart6-effort.png" class="pop" target="_blank">
                          <img src="images/study1/chart6-effort.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>


          </div>
        </div>




      <div class="card">
        <div class="card-header">
          <a class="collapsed card-link" data-toggle="collapse" href="#collapseTwo">
            <b>2. Usability of Voice Assistants for People with Acquired Brain Injury</b>
          </a>
        </div>
        <div id="collapseTwo" class="collapse" data-parent="#accordion1">
          <div class="card-body p-2">

            <!-- ************ TAB LABELS ************ -->
            <ul class="nav nav-tabs" role="tablist">
              <li class="nav-item">
                <a class="nav-link active" href="#overview12" role="tab" data-toggle="tab">Overview</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#methods12" role="tab" data-toggle="tab">Methods</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#results12" role="tab" data-toggle="tab">Results</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#graphs12" role="tab" data-toggle="tab">Graphs & Charts</a>
              </li>
            </ul>
            <!-- ************ TAB LABELS ************ -->


            <!-- ************ TAB CONTENT ************ -->
            <div class="container p-0">
              <div class="tab-content">
                <div role="tabpanel" class="tab-pane active p-3" id="overview12">
                  <p>
                    <b>Voice Assistants</b> (VAs), speech-operated smart assistants like Apple’s Siri and Amazon’s Alexa, offer the potential to support the everyday functioning of people with Acquired Brain Injury (ABI),
                    offering increased accessibility and quick task completion through their hands-free and eyes-free interface.
                    Research, however, has shown that the majority of users use VAs for a very limited number of activities, and their frequency of use and user satisfaction can be affected by different factors.
                    Additionally, their use in the context of brain injury rehabilitation has not been thoroughly examined in research.
                  </p>
                  <p>
                    The objectives of these studies were to investigate the usability and overall user experience of Voice Assistants, when used by people with cognitive impairments due to ABI.
                    A case-study report can be found <a href="2.VA_usability.pdf" target="_blank">here.</a>
                    More details <a href="2021malapaschasphd.pdf#page=96" target="_blank">here.</a>
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="methods12">
                  <h5>Study 3 - Focus Groups</h5>
                  <p>
                    A set of focus groups with people with ABI (n=29) eliciting details about the use of assistive technologies, as well as introducing the concept of VAs as cognitive aids and acquiring initial feedback.
                    The participants were users of three different services for brain injury rehabilitation in Scotland and Greece.
                    Each focus group session consisted of three parts: 1) Introduction and discussion about the effects of ABI;
                    2) The use of tools and strategies to compensate for cognitive deficits; and 3) The use of Voice Assistants as cognitive aids.
                    Deductive (theoretical) thematic analysis was used to analysed the recorded data, using a framework created from the results of previous studies and the related literature.
                  </p>

                  <h5>Study 4 - Online Interviews</h5>
                  <p>
                    A set of online interviews with people with ABI (n=10) who use Voice Assistants on a regular basis, to to acquire information about how people with ABI use Voice Assistants, how they compare VAs to other tools, and what aspects of VAs they find particularly useful or problematic.
                    A semi-structured approach was applied, focusing on: 1) the participant’s background (their injury and its effects, and the type of cognitive aids/strategies used); 2) the use of VAs (how they use and experience the interaction with the technology); 3) ideas about potential VA features or applications that can benefit people with ABI.
                    The recorded data were analysed using Deductive Thematic Analysis, using codes based on the framework created by previous studies.
                  </p>

                  <h5>Study 5 - Usability Study</h5>
                  <p>
                    A lab study to investigate the usability of Voice Assistants for people with ABI (n=15), who were asked to use a VA to carry out different tasks and evaluate their experience.
                    The tasks ranged from performing simple queries (e.g. asking for the weather) to more complex tasks requiring the exchange of information with the system in a conversational way.
                    The participants evaluated their subjective evaluation of workload of each set of tasks through a NASA-TLX questionnaire. Finally, the participants filled in a User Experience Questionnaire (UEQ) to evaluate their overall experience of interacting with the VA.
                    Observational analysis was used to investigate the different issues that emerged during the participants’ interaction with the VAs.
                    Statistical analysis was used to examine the difference between the three sets of tasks, in the different types of errors identified, and the subjective workload.
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade px-3 pt-3 pb-1" id="results12">
                  <p>
                    The results of the studies were analysed to determine the different factors that can affect the usability of VAs, which designers of technology need to consider when developing applications for people with ABI:
                  </p>
                  <table class="table table-striped smalltext">
                    <thead>
                      <tr>
                        <th><h4>Factor</h4></th>
                        <th><h4>Impact on Usability</h4></th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td><b>Memory</b></td>
                        <td>
                          Forgetting to use the VA <br>
                          Forgetting to carry out the task after receiving a reminder <br>
                          Unable to remember what a prompt is in reference to <br>
                          Forgetting trigger phrase, required keywords/phrases <br>
                          Forgetting how to structure queries/commands <br>
                          Unable to retain required information during input of single-utterance queries Unable to retain responses consisting of lists of items <br>
                        </td>
                      </tr>
                      <tr>
                        <td><b>Complexity of Interaction</b></td>
                        <td>
                          Significant association between cognitive difficulties and perceived mental demand <br>
                          Subjective workload affects evaluation of user experience <br>
                          User errors are more often in tasks with longer interactions <br>
                          Input errors are more often in long, single-utterance commands Editing information that has already been inserted is challenging Users prefer to use visual interaction for more complex tasks <br>
                        </td>
                      </tr>
                      <tr>
                        <td><b>Speech Recognition</b></td>
                        <td>
                          Can cause frustration <br>
                          Can result in input of incorrect information <br>
                          Common, but does not prevent people with ABI from using VAs <br>
                          Frequency of speech recognition errors can decrease over time <br>
                          Errors due to incorrect phrasing (not knowing how to structure query) are more frequent, but can be prevented with training <br>
                          Single-utterance input is more prone to S.R. errors <br>
                          Speech difficulties can improve over time <br>
                          Users with mild speech impairments can also benefit from VAs <br>
                        </td>
                      </tr>
                      <tr>
                        <td><b>Lack of Motivation/Self Awareness</b></td>
                        <td>
                          Not reacting to prompts/notifications <br>
                          Not initiating interaction with system <br>
                          Not recognising the system’s benefit <br>
                          Not realising the need for provided support <br>
                        </td>
                      </tr>
                      <tr>
                        <td><b>Change in Abilities</b></td>
                        <td>
                          Cognitive functioning can improve during recovery <br>
                          Cognitive performance can fluctuate due to fatigue
                        </td>
                      </tr>
                      <tr>
                        <td><b>Learning Difficulties</b></td>
                        <td>
                          Inability to search new features <br>
                          Forgetting how to use them after a certain period <br>
                          Experience does not help with successful completion of unknown tasks <br>
                        </td>
                      </tr>
                      <tr>
                        <td><b>Lack of Portability</b></td>
                        <td>
                          Inability to use outside the house (smart speakers) <br>
                          Missing prompts when not in proximity of speaker
                        </td>
                      </tr>
                      <tr>
                        <td><b>Privacy and Security</b></td>
                        <td>
                          Security concerns exist, but would not prevent sharing of personal information if adequately informed about data usage <br>
                          Privacy issues when used in front of others
                        </td>
                      </tr>
                    </tbody>
                  </table>
                  <br>
                  <p>Additionally, a comprehensive list of use cases of Voice Assistants for people with ABI was created through the analysis of the results, determining the situations where the use of VAs would be appropriate and beneficial:</p>

                  <table class="table table-striped smalltext">
                    <thead>
                      <tr>
                        <th><h4>Targeted Area</h4></th>
                        <th><h4>Use Cases</h4></th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td><b>Prospective Memory</b></td>
                        <td>Reminders, alarms and timers to remind users of upcoming tasks and events</td>
                      </tr>
                      <tr>
                        <td><b>Organisation</b></td>
                        <td>Calendar management, reminders, speech-based applications for applying problem solving strategies</td>
                      </tr>
                      <tr>
                        <td><b>Long-term memory</b></td>
                        <td>Note taking, storing autobiographical memories, self monitoring</td>
                      </tr>
                      <tr>
                        <td><b>Inappropriate behaviour</b></td>
                        <td>Prompts to notify users when behaving inappropriately, reminders for relevant rehabilitation strategies</td>
                      </tr>
                      <tr>
                        <td><b>Initiation and motivation</b></td>
                        <td>Prompts to encourage activity, self-monitoring and rewards</td>
                      </tr>
                      <tr>
                        <td><b>Communication</b></td>
                        <td>Speaking practice and exercises, send/receive messages to/from carers, family members, therapists and other ABI survivors</td>
                      </tr>
                      <tr>
                        <td><b>Cognitive training</b></td>
                        <td>Speech-based cognitive rehabilitation exercises</td>
                      </tr>
                      <tr>
                        <td><b>Support from carers/family</b></td>
                        <td>Convey messages indirectly from carers/family, to reduce conflict and increase sense of self-dependence</td>
                      </tr>
                      <tr>
                        <td><b>Assessment</b></td>
                        <td>Monitor task completion and gather data to inform rehabilitation and therapy sessions</td>
                      </tr>
                      <tr>
                        <td><b>Accessibility of external aids</b></td>
                        <td>Provide alternative speech-based interaction method for currently used external aids</td>
                      </tr>
                      <tr>
                        <td><b>Efficiency of external aids</b></td>
                        <td>Encourage and facilitate use of other external aids</td>
                      </tr>

                    </tbody>
                  </table>


                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="graphs12">

                  <div class="container p-3">
                    <div class="row">
                      <div class="col-sm">
                        <a href="./images/study2/chart21.png" class="pop" target="_blank">
                          <img src="images/study2/chart21.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study2/chart22.png" class="pop" target="_blank">
                          <img src="images/study2/chart22.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study2/chart23.png" class="pop" target="_blank">
                          <img src="images/study2/chart23.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study2/chart24.png" class="pop" target="_blank">
                          <img src="images/study2/chart24.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                    </div>
                    <div class="row pt-3">
                      <div class="col-sm">
                        <a href="./images/study2/chart25.png" class="pop" target="_blank">
                          <img src="images/study2/chart25.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study2/chart26.png" class="pop" target="_blank">
                          <img src="images/study2/chart26.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study2/chart27.png" class="pop" target="_blank">
                          <img src="images/study2/chart27.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                      <div class="col-sm">
                        <a href="./images/study2/chart28.png" class="pop" target="_blank">
                          <img src="images/study2/chart28.png" class="img-thumbnail hover-shadow" style="width: 400px;">
                        </a>
                      </div>
                    </div>
                  </div>



                </div>
              </div>
            </div>
            <!-- ************ TAB CONTENT ************ -->
          </div>
        </div>
      </div>

      <div class="card">
        <div class="card-header">
          <a class="collapsed card-link" data-toggle="collapse" href="#collapseThree">
            <b>3. Designing a Voice Assistant-based Prompting System</b>
          </a>
        </div>

        <div id="collapseThree" class="collapse" data-parent="#accordion1">
          <!-- ************ TAB LABELS ************ -->
          <ul class="nav nav-tabs" role="tablist">
            <li class="nav-item">
              <a class="nav-link active" href="#overview13" role="tab" data-toggle="tab">Overview</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#design13" role="tab" data-toggle="tab">Prototype Design</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#methods13" role="tab" data-toggle="tab">Methods</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="#results13" role="tab" data-toggle="tab">Results</a>
            </li>
          </ul>
          <!-- ************ TAB LABELS ************ -->

          <!-- ************ TAB CONTENT ************ -->
          <div class="container p-0">
            <div class="tab-content">
              <div role="tabpanel" class="tab-pane active p-3" id="overview13">
                <p>
                  The cognitive effects of a brain injury can limit the usability, and affect the user experience of Voice Assistants.
                  This study aimed to assess the efficacy and applicability of different identified design solutions, and look for new methods to increase the usability of VAs for people with ABI.
                </p>
                <p>
                  This was accomplished through the evaluation of the design of a prototype VA-based prompting system, which aims to increase the independence of people with cognitive impairments due to ABI.

                  A case-study report can be found <a href="3.VAdesign.pdf" target="_blank">here.</a>
                  More details <a href="2021malapaschasphd.pdf#page=137" target="_blank">here.</a>
                </p>
              </div>
              <div role="tabpanel" class="tab-pane fade p-3" id="design13">
                <p>
                  <b>Mindframe</b>, the prototype designed for the purposes of this study, is a multi-functional skill for Amazon’s Voice Assistant (Alexa), which enables people who provide support to a person with ABI (professional carers, family members, therapists) schedule prompts through a web or mobile interface. The prompts are then conveyed to the end user (person with ABI) through a smart speaker (Amazon Echo) in an unsolicited manner, at the programmed time and date. Mindframe also enables users to use its Voice User Interface to: 1) Receive a list of all the reminders programmed for a specific day; 2) Receive a list of missed or unconfirmed reminders; 3) Create new reminders, and 4) Modify or delete existing reminders.
                </p>
                <img src="./images/study3/Mindframe.png" alt="Mindframe" width="100%">
              </div>
              <div role="tabpanel" class="tab-pane fade p-3" id="methods13">
                <p>
                  The VUI of the prototype was evaluated through an <b>Expert Review</b> study with eight experts in the fields of Human-Computer Interaction (HCI) (n=4) and brain injury rehabilitation (n=4). The participants were presented with the different aspects of the system’s interface and provided feedback on its design. The results were analysed to determine how the VUI of the prototype should be designed to: 1) Convey information to the user; 2) Provide prompts; 3) Enable users to insert information to the system, 4) Monitor and assess the user’s activity, and 5) Increase the system’s learnability.
                </p>
                <p>
                  The <b>System in the Loop</b> method was used for the development and evaluation of the prototype, implementing only the functionality of the system that was needed to collect the required data. The participants of the study interacted with the skill through the testing simulator provided by Amazon’s Alexa developer’s console.
                </p>
                <p>
                  A set of <b>storyboards</b> were used to explain the concept of the prototype to the participants, as well as different discussion topics (such as potential challenges in using the system). Two different <b>personas</b> of potential users were created based on data collected from previous studies, which were shown to the participants at the beginning of the study, outlining some of the most common difficulties in people with ABI that were found to affect the usability of VAs.
                </p>
                <p>
                  The participants were asked to interact with the prototype to perform the following tasks:
                  1. Receive the day’s schedule; 2. Receive a reminder; 3. Create a reminder; 4. Edit a reminder.
                  For each task, a number of different versions of the VUI had been implemented, employing different approaches in the design of the interface based on results from previous studies. Each task was repeated a certain number of times, enabling participants to interact with the system using the different versions of the VUI.
                  After completing the tasks, the participants were asked to provide insights on the design of the prototype’s VUI in the following areas:
                  1. Confirmations for task completion; 2. Teaching users how to use the system; 3. Monitoring the user’s activity.
                </p>
              </div>
              <div role="tabpanel" class="tab-pane fade px-3 pt-3 pb-1" id="results13">
                <p>
                  The transcribed data were analysed using Deductive Thematic Analysis, the framework for which was based on the objectives of this research.
                  The findings were analysed to create a set of design guidelines for VA-based prompting systems, for people with Acquired Brain Injury:
                </p>
                <table class="table table-striped smalltext">
                  <tbody>
                    <tr>
                      <td><b><h5>List of reminders/tasks</h5></b></td>
                    </tr>
                    <tr>
                      <td>
                        1. Memorisation of list items should not be expected, regardless of the list’s size. <br>
                        2. Can be useful for providing an overview of daily tasks/schedule.<br>
                        3. First item should be emphasised/re-iterated (in the case of upcoming tasks).<br>
                        4. Items on the list should be prioritised based on their importance, or execution time (for tasks).<br>
                        5. Users should be informed of the current time.<br>
                        6. Search functionality for specific items should be provided, after the list is conveyed.<br>
                        7. Easier to process when the user is looking for a specific item on the list (e.g. when changing a reminder).<br>
                        8. Repetition can cause frustration but is recommended, if the contained items are part of the user’s schedule.<br>
                        9. Easier to process or retain when the user is familiar with the contained information.
                      </td>
                    </tr>
                    <tr>
                      <td><b><h5>Reminding prompts</h5></b></td>
                    </tr>
                    <tr>
                      <td>
                        1. Unsolicited prompts are useful, but depend on user’s proximity to the device. <br>
                        2. Users are unlikely to react to the notification indication of smart speakers (light).<br>
                        3. Important or urgent missed prompts should be repeated at regular intervals, until user confirmation.<br>
                        4. Current time should be provided, if relevant.<br>
                        5. Should be phrased to prompt immediate action.
                      </td>
                    </tr>
                    <tr>
                      <td><b><h5>Confirmation prompts</h5></b></td>
                    </tr>
                    <tr>
                      <td>
                        1. Require different wording than the original prompt. <br>
                        2. Should allow users to mark prompts as delivered, or tasks as completed by:<br>
                        &nbsp&nbspa. Allowing users to unpromptedly notify the system that they have completed a task. <br>
                        &nbsp&nbspb. Being phrased as questions, expecting a yes/no answer from the user.<br>
                        3. Should be repeated at regular intervals, until user confirmation (where applicable).
                      </td>
                    </tr>
                    <tr>
                      <td><b><h5>Information input</h5></b></td>
                    </tr>
                    <tr>
                      <td>
                        1. Ensuring correct information input is essential in the case of reminders.<br>
                        2. Single-utterance input is very demanding when containing multiple pieces of information (e.g. creating a reminder)<br>
                        3. Breaking down input to small steps (one piece of information at a time) can improve information recall and input errors.<br>
                        4. Open-ended questions (e.g. ‘what would you like to do’) can be confusing and lead to input errors.<br>
                        5. Confirmation dialogues should be given only once, after input completion, offering the option to start over or change a
                        specific item in the case of an error.<br>
                        6. Switching between interface modes (e.g. from structured to flexible) should be decided by the carer/therapist.
                      </td>
                    </tr>
                    <tr>
                      <td><b><h5>System Help</h5></b></td>
                    </tr>
                    <tr>
                      <td>
                        1. User tutorial should be provided which:  <br>
                        &nbsp&nbsp a. Is automatically enabled the first time the system is used.  <br>
                        &nbsp&nbsp b. Walks users through the completion of training tasks, giving detailed instructions and feedback for every step. <br>
                        2. A ‘help’ command should be available, providing the following options:  <br>
                        &nbsp&nbsp a. Describe of what the system can be used for, providing example queries.  <br>
                        &nbsp&nbsp b. Launch the tutorial for a specific function.  <br>
                        &nbsp&nbsp c. Provide guidance for the task currently performed by the user. <br>
                        3. Help should be given automatically when the system detects consecutive errors, or phrases like ‘I don’t know what to do’.
                      </td>
                    </tr>
                    <tr>
                      <td><b><h5>Monitoring</h5></b></td>
                    </tr>
                    <tr>
                      <td>
                        1. Users should be asked to input their activity, once per day, at a specific time. <br>
                        2. Users should be asked to confirm the completion of specific activities in their schedule. Open-ended questions should be avoided (e.g. ‘what did you do today’).
                      </td>
                    </tr>

                  </tbody>
                </table>
              </div>
            </div>
          </div>
          <!-- ************ TAB CONTENT ************ -->

        </div>
      </div>

    </div>

    <br><br>
    <!-- **************** ACCORDION 2 **************** -->
    <div class="container pb-2">
      <h2>Technology-mediated Co-located Interaction</h2>
    </div>

    <div id="accordion2" class="px-2">

      <div class="card">
        <div class="card-header">
          <a class="card-link" data-toggle="collapse" href="#collapseFour">
            <b>1. A Proximity-Based Social Application Aiming to Encourage Interaction between Nearby People</b>
          </a>
        </div>
        <div id="collapseFour" class="collapse" data-parent="#accordion2">
          <div class="card-body p-2">

            <!-- ************ TAB LABELS ************ -->
            <ul class="nav nav-tabs" role="tablist">
              <li class="nav-item">
                <a class="nav-link active" href="#overview21" role="tab" data-toggle="tab">Overview</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#design21" role="tab" data-toggle="tab">Prototype Design</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#methods21" role="tab" data-toggle="tab">Methods</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#results21" role="tab" data-toggle="tab">Results</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#publications21" role="tab" data-toggle="tab">Publications</a>
              </li>
            </ul>
            <!-- ************ TAB LABELS ************ -->

            <!-- ************ TAB CONTENT ************ -->
            <div class="container p-0">
              <div class="tab-content">
                <div role="tabpanel" class="tab-pane active p-3" id="overview21">
                  <p>
                    This research examined the potential that proximity-based applications can have in encouraging interaction between nearby people.
                    <b>Next to you</b>, a prototype social application developed at the <a href="http://www.tut.fi/en/social-technologies/solutions--publications/index.htm">University of Tampere</a> applies gamification to increase awareness of nearby people and encourage social interaction.
                  </p>
                  <p>
                    The prototype's code can be found <a href="https://github.com/arisms/n2u" target="_blank">here.</a>
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="design21">
                  <p>
                    The users create their profile by uploading a profile picture and inserting “whispers”. After at least one whisper has been saved, the user’s profile is activated and can be discovered by other users.
                    The main view contains a list of connections discovered by the user. The first time two users are within each other’s proximity (Bluetooth range), a connection between them is created, and their first whispers are exchanged. Users can edit their whispers and rearrange their order, determining which will be received first by their connections.
                  </p>
                  <img src="./images/study4/n2u1.gif" alt="Next to you 1" width="96%">
                  <p>
                    If two users meet again (after at least 5 hours have passed), another exchange of whispers automatically takes place. Users cannot receive more whispers (from each connection) than they have created in their own profile. By tapping on a connection, a user can view another user’s profile, containing the whispers they have received from them (depending on how many times they have met). The user can tap and hold on a whisper to like it.
                  </p>
                  <img src="./images/study4/n2u2.png" alt="Next to you 2" width="96%">
                  <p>
                    After a connection between two users has been established, they can exchange text messages by navigating to each other’s profile and tapping on the “Messages” button. If they are in proximity, they can initiate a Face-to-Face confirmation: an image containing 5 figures is shown on user’s A screen, and one of the 5 figures is randomly shown on user’s B screen. User B needs to show his/her screen to user A (provided that they are meeting face-to-face), and user B needs to tap on the corresponding figure on his/her own screen. The process must be repeated successfully 3 times, before a countdown timer runs out! After the confirmation is completed, the users cannot repeat it until the next time they meet. The first time a successful F2F confirmation is achieved, the two users unlock each other’s profile picture, which is now visible on their profile and list of connections.
                  </p>
                  <img src="./images/study4/n2u3.png" alt="Next to you 3" width="96%">
                  <p>The users are awarded with unlocking achievements for using the application further: collecting more profiles, receiving many likes for a whisper, sending and receiving messages etc. Each achievement has three ranks; bronze, silver and gold. The users are notified when a new contact is in proximity through push notifications, or when they have received a new whisper from an existing connection, when one of their whispers has been liked, when they have received a message or F2F request, or when they have unlocked an achievement.</p>
                  <img src="./images/study4/n2u4.png" alt="Next to you 4" width="96%">
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="methods21">
                  <p>
                    A set of <b>focus groups</b> were conducted to evaluate the design concept (n=18 participants). Based on the results, there was a second development iteration to improve the design and implement additional features.
                  </p>
                  <p>
                    A <b>field trial</b> with 162 participants was conducted to evaluate the effectiveness of the application, investigating the application's overall user experience over a period of seven weeks. The study was held at two university campuses. Usage data were collected from each participant. In addition, participants evaluated their experience through two online questionnaires, the 1st one week after installing the app, and the 2nd at the end of the field trial.
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="results21">
                  <p>
                    The application managed to encourage various interactions that we argue would not have otherwise taken place. The specific effect of the designed features was challenging to measure, which was made more challenging by insufficient critical density and practical limitations in the trial. <br><br>
                    Based on the findings we provide a list of design considerations for applications aiming to encourage social interaction among strangers, and similar evaluation trials, including the following: 1) Adjusting the definition of "nearby" based on the context and location of use could be crucial to forming a critical density of users early on; 2) Offer users information about where to look for nearby users using GPS technology (without revealing their exact location due to privacy concerns), and award the discovery of other users through the achievement system, supporting progression; 3) Include means to ensure good quality of shared content, e.g. through promoting 'liked' information and demoting 'disliked' whispers; 4) Support engagement with the application through a content feed, which gives easier access to shared content from nearby users.
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="publications21">
                  <p>Susanna Paasovaara, Kaisa Väänänen, Aris Malapaschas, Ekaterina Olshannikova, Thomas Olsson, Pradthana Jarusriboonchai, Jiří Hošek, and Pavel Mašek. 2018. Playfulness and progression in technology-enhanced social experiences between nearby strangers. In Proceedings of the 10th Nordic Conference on Human-Computer Interaction (NordiCHI '18). Association for Computing Machinery, New York, NY, USA, 537–548. DOI:<a href="https://doi.org/10.1145/3240167.3240212" target="_blank">https://doi.org/10.1145/3240167.3240212</a></p>

                  <p>Susanna Paasovaara, Ekaterina Olshannikova, Pradthana Jarusriboonchai, Aris Malapaschas, and Thomas Olsson. 2016. Next2You: a proximity-based social application aiming to encourage interaction between nearby people. In <i>Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia</i> (<i>MUM '16</i>). Association for Computing Machinery, New York, NY, USA, 81–90. DOI:<a href="https://doi.org/10.1145/3012709.3012742" target="_blank">https://doi.org/10.1145/3012709.3012742</a></p>

                  <p>Susanna Paasovaara, Ekaterina Olshannikova, Pradthana Jarusriboonchai, Aris Malapaschas, and Thomas Olsson. 2016. Next2You: a social application for nearby strangers. In <i>Proceedings of the 15th International Conference on Mobile and Ubiquitous Multimedia</i> (<i>MUM '16</i>). Association for Computing Machinery, New York, NY, USA, 339–341. DOI:<a href="https://doi.org/10.1145/3012709.3016063" target="_blank">https://doi.org/10.1145/3012709.3016063</a></p>
                </div>
              </div>
            </div>
            <!-- ************ TAB CONTENT ************ -->

          </div>
        </div>
      </div>

      <div class="card">
        <div class="card-header">
          <a class="collapsed card-link" data-toggle="collapse" href="#collapseFive">
            <b>2. Design and Evaluation of a Multi-Player Mobile Game for Icebreaking Activities</b>
          </a>
        </div>
        <div id="collapseFive" class="collapse" data-parent="#accordion2">
          <div class="card-body p-2">

            <!-- ************ TAB LABELS ************ -->
            <ul class="nav nav-tabs" role="tablist">
              <li class="nav-item">
                <a class="nav-link active" href="#overview22" role="tab" data-toggle="tab">Overview</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#design22" role="tab" data-toggle="tab">Prototype Design</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#methods22" role="tab" data-toggle="tab">Methods</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#results22" role="tab" data-toggle="tab">Results</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#publications22" role="tab" data-toggle="tab">Publications</a>
              </li>
            </ul>
            <!-- ************ TAB LABELS ************ -->

            <!-- ************ TAB CONTENT ************ -->
            <div class="container p-0">
              <div class="tab-content">
                <div role="tabpanel" class="tab-pane active p-3" id="overview22">
                  <p>
                    Ice-breaking activities can create a positive atmosphere, relieve tension or formality in a group of strangers and encourage early participation and collaboration in social activities. The goal of this study was to explore how interactive technology can facilitate icrebreaking activities and support collaboration in the context of a group of collocated strangers.
                  </p>
                  <p>For this purpose, we designed and implemented Who's Next, a prototype mobile quiz-based game aiming to help a group of strangers to get to know each other, drawing inspiration from traditional collocated games for children and party games such as Truth or Dare. The prototype's design was evaluated using an exploratory, group-based user study assessing the potential of the application in its intended purpose and context of use, and investigating the possible social implications and user experiences of playing the game.</p>
                  <p>
                    The prototype's code can be found <a href="https://github.com/arisms/whosnext" target="_blank">here.</a>
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="design22">
                  <p>
                    Who’s Next is a group-based (3 to 10 players), face-to-face quiz game about personal information. It aims to facilitate group members to get to know each other and break the ice during their first encounter. <br>
                    At first the players answer a set of questions about themselves, some of which encourage them to share interesting and personal details about themselves. During the game the players are supposed to select the correct person behind a given answer to a question. During game set-up, the user creating the game selects the group of questions asked in the beginning (based on the level of familiarity between the players) and the game duration.
                  </p>
                  <img src="./images/study5/wn1.png" alt="Who's next 1" width="96%">
                  <p>
                    Before the game starts, each player fills in his or her name and answers a short list of provided questions related to him or herself. After all players have answered a predefined list of questions (see Table 1 and Figure 1: left), the game starts and one of the players will have the turn – the active player. The task for the player in turn is to find out who is the other player who gave the specific answer to the question.
                  </p>
                  <img src="./images/study5/wn2.png" alt="Who's next 2" width="96%">
                  <p>
                    The active device shows a randomly selected question from the list, an answer from one of the players to that question, and a list of other players’ names to choose from. The other players have an inactive display simply stating “Please wait…” The game continues in the same manner for every player until the predefined time runs out or all the players’ answers have been used.
                  </p>
                  <img src="./images/study5/wn3.png" alt="Who's next 3" width="96%">
                  <p>The devices are connected via Wi-Fi direct (using the Wi-Fi Peer-to-Peer API), enabling connectivity of multiple devices within the range of each other without the need for a separate wireless access point or internet connection. One device acts as a server and others are clients. The server keeps track of the questions and answers being used (with the help of an SQLite database), randomly selects a pair of stored question-answer for each turn, selects which device will be up next, and broadcasts the messages to all the devices. When the countdown timer reaches 0 or all the elements from the question-answer list have been used, the game is over. The ending message is then broadcast to the clients.</p>
                  <img src="./images/study5/wn4.png" alt="Who's next 4" width="80%">
                  <p>Each device is responsible for keeping track of its player performance (number of mistakes made and rounds completed), and calculating the user's individual score. All individual scores are transmitted back to the master device, which then calculates the group's total score.</p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="methods22">
                  <p>
                    A group-based user study consisting of six groups of strangers and acquaintances (n=28 participants). Each session consisted of an introduction phase, during which the participants filled in the answers to a pre-defined list of 8 questions and familiarized themselves with the rules and logic of the game, and three rounds of playing the game.
                  </p>
                  <p>
                    Video and audio recordings were used to observe and record the participants’ behavior while playing the game. At the end of each session, a group discussion was held to assess the players’ subjective experiences and to receive feedback about the overall concept of the game. The recordings were transcribed and coded based on the interaction that emerged between the participants during the study, and were analyzed using qualitative content analysis, with an affinity diagram that produced a data-driven and bottom-up hierarchy of themes.
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="results22">
                  <p>
                    The game was found successful in providing the participants with a comfortable way of sharing information about oneself and getting to know newly-met strangers and distant acquaintances. It created a playful and relaxed atmosphere and managed to encourage players to interact with each other. It managed to foster face-to-face interaction and keep everyone engaged throughout the game, even while waiting for their turns. Rich interactions and collaboration were observed, and the participants gradually became more relaxed and playful with each other. After only three rounds of game play, the players remembered not only the names of the other players but also various interesting facts about them.
                  </p>
                  <p>We argue that Who’s Next has strong potential as a tool to facilitate icebreaking activity. We conclude that even a relatively simple mobile application can have a central role in facilitating activities that are traditionally very socially defined and require human facilitators. Who’s Next allows icebreaking to be led by the game, requiring only simple human facilitation in the form of triggering the start of the game.</p>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/B0Cxq-0c_fE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="publications22">
                  <p>Jarusriboonchai, P., Malapaschas, A., Olsson, T. (2016) <a href="http://dl.acm.org/citation.cfm?id=2858298&amp;CFID=832617956&amp;CFTOKEN=78264711">Design and Evaluation of a Multi-Player Mobile Game for Icebreaking Activity</a>. CHI '16: Proceedings of the 2016 CHI Conference on Human Factors in Computing SystemsMay 2016. Pages 4366–4377. https://doi.org/10.1145/2858036.2858298</p>

                  <p>Aris Malapaschas (2015) <a href="https://trepo.tuni.fi/handle/123456789/22906"> Design and Evaluation of a Playful Mobile Application to Facilitate Group Interaction.</a> Master's Thesis, Tampere University of Technology.</p>
                </div>
              </div>
            </div>
            <!-- ************ TAB CONTENT ************ -->


          </div>
        </div>
      </div>

      <div class="card">
        <div class="card-header">
          <a class="collapsed card-link" data-toggle="collapse" href="#collapseSix">
            <b>3. Increasing Collocated People’s Awareness of the Mobile User’s Activities</b>
          </a>
        </div>
        <div id="collapseSix" class="collapse" data-parent="#accordion2">
          <div class="card-body p-2">

            <!-- ************ TAB LABELS ************ -->
            <ul class="nav nav-tabs" role="tablist">
              <li class="nav-item">
                <a class="nav-link active" href="#overview23" role="tab" data-toggle="tab">Overview</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#design23" role="tab" data-toggle="tab">Prototype Design</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#methods23" role="tab" data-toggle="tab">Methods</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#results23" role="tab" data-toggle="tab">Results</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" href="#publications23" role="tab" data-toggle="tab">Publications</a>
              </li>
            </ul>
            <!-- ************ TAB LABELS ************ -->

            <!-- ************ TAB CONTENT ************ -->
            <div class="container p-0">
              <div class="tab-content">
                <div role="tabpanel" class="tab-pane active p-3" id="overview23">
                  <p>
                    Social display is a prototype that provides visual cues about the mobile user's current activity with the device, which are shown on a display attached to the backside of the mobile device. The purpose of this study was to examine the possible social effects of increasing surrounding people's awareness of one's activity on the smartphone.
                  </p>
                  <p>The prototype was designed through an iterative process of focus groups, and its final design was evaluated through a field trial of using social display in real life situations for 10 days. The findings provide insights that can be used for designing technologies aiming to increase activity awareness and enhance social interactions between collocated people.</p>
                  <p>
                    The prototype's code can be found <a href="https://github.com/arisms/SocialDisplay3" target="_blank">here.</a>
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="design23">
                  <img src="./images/study6/sd1.png" alt="Social Display 1" width="80%">
                  <p>The prototype consists of a 3.5-inch <a href="http://www.inkcase.com/">E-Ink display</a> attached to the backside of an Android smartphone to which images are transmitted from the smartphone via Bluetooth. The Social Display app identifies the application that is currently running in the foreground of the user's phone and sends an appropriate image to the display, making it possible for people around the user to see which application on the mobile device he is using at the moment.</p>
                  <img src="./images/study6/sd2.gif" alt="Social Display 2" width="96%">
                  <p>
                    The user can create different profiles for the app, which can later be activated or deactivated. For each profile the user can select from a list of all the applications that are installed on the phone, which will be shown on the display when being used. The user also adds a picture from his gallery to show on the display when the phone is inactive, or when one of the non-selected applications is used. If a profile is set as active, it is automatically enabled when the user goes to a specific location (either identified by the WiFi network or the GPS location).
                  </p>
                  <img src="./images/study6/sd3.png" alt="Social Display 3" width="96%">
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="methods23">
                  <p>
                    The concept was first introduced in a <b>focus group</b> through <b>scenarios</b> and <b>paper-based mock-ups</b>. We explored the perceived opportunities and challenges of the concept with both scenario-based interviewing and by co- designing the visual cues together with the participants. The results of the focus group study were used to finalize the design and build the prototype.
                  </p>
                  <p>
                    To evaluate the prototype, a <b>field trial</b> with 13 participants in a qualitative approach was conducted. For each participant, the study consisted of 10-12 days of using the prototype, with his or her own smartphone. At the beginning of the trial, each participant was interviewed about their general attitude and behavior about privacy and their use of smartphones in everyday life, and answered an initial questionnaire regarding their first impressions and expectations of the prototype, as well as their viewpoints on certain privacy-related issues of phone usage. In the evening of each day during the trial period, the participants provided answers to a short questionnaire regarding their experience with the social display during that day. A second interview meeting was arranged with every participant at the end of the trial period, during which they were asked about their experience and interactions during the study.
                  </p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="results23">
                  <p>
                    The results imply that the social display has the potential to increase activity awareness and occasionally encourage serendipitous interaction between mobile device users and their collocated family members and friends. Additionally, the social display underlines the user’s activities with their mobile devices, thus raising self- awareness regarding the appropriateness of using mobile devices in different social contexts. The social display was found to encourage its users to be more careful with the usage of their mobile devices, and, before using them, consider ongoing activities around them more carefully.</p>
                </div>
                <div role="tabpanel" class="tab-pane fade p-3" id="publications23">
                  <p>Jarusriboonchai, P., Olsson, T., Väänänen-Vainio-Mattila, K. (2015) <a href="http://dl.acm.org/citation.cfm?id=2785863&amp;CFID=832617956&amp;CFTOKEN=78264711">Social Displays on Mobile Devices: Increasing Collocated People's Awareness of the User's Activities</a>. MobileHCI 2015, Copenhagen, Denmark. ACM Press.</p>

                  <p>Jarusriboonchai, P., Olsson, T., Malapaschas, A., Väänänen, K. (2016) <a href="http://dl.acm.org/citation.cfm?id=2819990&amp;CFID=832617956&amp;CFTOKEN=78264711">Increasing Collocated People's Awareness of Mobile User's Activities: Field Trial of Social Display</a>. CSCW'16, San Francisco, USA. ACM Press.</p>
                </div>
              </div>
            </div>
            <!-- ************ TAB CONTENT ************ -->

          </div>
        </div>
      </div>

    </div>

  </div>
</div>
</div>


<!-- ************************ FOOTER ************************ -->
  <div class="container-fluid header pt-2 pb-2">
    <div class="row">
      <div class="col-sm"></div>
      <div class="col-sm"></div>
      <div class="col-sm"></div>
      <div class="col-sm float-right">
        <div class="clearfix pr-2">
          <span class="float-right">
            <a href="mailto:aris.malapaschas@gmail.com" target="_blank" class="pr-2">
              <img src="./images/Mail.png" alt="Send Email" width="30px;">
            </a>
            <a href="https://www.linkedin.com/in/aris-malapaschas/" target="_blank" class="pr-2">
              <img src="./images/Linkedin.png" alt="Linked In" width="30px;">
            </a>
            <a href="https://twitter.com/ArisMalapaschas?s=20" target="_blank" class="pr-2">
              <img src="./images/Twitter.png" alt="Twitter" width="30px;">
            </a>
            <a href="https://github.com/arisms" target="_blank" class="pr-2">
              <img src="./images/Github.png" alt="Twitter" width="28px;">
            </a>
            <a href="https://scholar.google.com/citations?user=uiIm2AIAAAAJ&hl=en" target="_blank" class="pr-1">
              <img src="./images/Scholar.png" alt="Google Scholar" width="32px;">
            </a>
          </span>
        </div>
      </div>
    </div>
  </div>
<!-- ************************ FOOTER ************************ -->



  </body>



</html>
